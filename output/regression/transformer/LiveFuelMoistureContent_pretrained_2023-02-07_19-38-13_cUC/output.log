Running:
src/main.py --output_dir ../../output/regression/transformer --comment pretraining through imputation --name LiveFuelMoistureContent_pretrained --records_file Imputation_records.xls --data_dir ../../data/LiveFuelMoistureContent --data_class tsra --pattern TRAIN --val_ratio 0.2 --epochs 10 --lr 0.001 --optimizer RAdam --batch_size 128 --pos_encoding learnable --d_model 64

Using device: cpu
Loading and preprocessing data ...
2794 samples may be used for training
699 samples will be used for validation
0 samples will be used for testing
Creating model ...
Model:
TSTransformerEncoder(
  (project_inp): Linear(in_features=7, out_features=64, bias=True)
  (pos_enc): LearnablePositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (transformer_encoder): TransformerEncoder(
    (layers): ModuleList(
      (0): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (1): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
      (2): TransformerBatchNormEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
        )
        (linear1): Linear(in_features=64, out_features=256, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=256, out_features=64, bias=True)
        (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (output_layer): Linear(in_features=64, out_features=7, bias=True)
  (dropout1): Dropout(p=0.1, inplace=False)
)
Total number of parameters: 174279
Trainable parameters: 174279
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 29.17846393585205 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 29.17846393585205 seconds
Avg batch val. time: 4.863077322642009 seconds
Avg sample val. time: 0.041743152984051575 seconds
Epoch 0 Validation Summary: epoch: 0.000000 | loss: 47.849287 | 
Starting training...
Epoch 1 Training Summary: epoch: 1.000000 | loss: 1.086065 | 
Epoch runtime: 0.0 hours, 10.0 minutes, 44.72862887382507 seconds

Avg epoch train. time: 0.0 hours, 10.0 minutes, 44.72862887382507 seconds
Avg batch train. time: 29.305846766992047 seconds
Avg sample train. time: 0.2307546989526933 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 30.293127059936523 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 29.735795497894287 seconds
Avg batch val. time: 4.955965916315715 seconds
Avg sample val. time: 0.04254047996837523 seconds
Epoch 1 Validation Summary: epoch: 1.000000 | loss: 0.976601 | 
Epoch 2 Training Summary: epoch: 2.000000 | loss: 0.869058 | 
Epoch runtime: 0.0 hours, 10.0 minutes, 54.43681216239929 seconds

Avg epoch train. time: 0.0 hours, 10.0 minutes, 49.58272051811218 seconds
Avg batch train. time: 29.526487296277825 seconds
Avg sample train. time: 0.2324920259549435 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 24.07586908340454 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 27.849153359731037 seconds
Avg batch val. time: 4.641525559955173 seconds
Avg sample val. time: 0.039841421115495046 seconds
Epoch 2 Validation Summary: epoch: 2.000000 | loss: 0.781290 | 
Epoch 3 Training Summary: epoch: 3.000000 | loss: 0.673872 | 
Epoch runtime: 0.0 hours, 11.0 minutes, 7.831423997879028 seconds

Avg epoch train. time: 0.0 hours, 10.0 minutes, 55.66562167803443 seconds
Avg batch train. time: 29.80298280354702 seconds
Avg sample train. time: 0.2346691559334411 seconds
Epoch 4 Training Summary: epoch: 4.000000 | loss: 0.542924 | 
Epoch runtime: 0.0 hours, 10.0 minutes, 51.15594029426575 seconds

Avg epoch train. time: 0.0 hours, 10.0 minutes, 54.538201332092285 seconds
Avg batch train. time: 29.751736424186014 seconds
Avg sample train. time: 0.23426564113532294 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 23.150684356689453 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 26.674536108970642 seconds
Avg batch val. time: 4.445756018161774 seconds
Avg sample val. time: 0.03816099586404956 seconds
Epoch 4 Validation Summary: epoch: 4.000000 | loss: 0.484880 | 
Epoch 5 Training Summary: epoch: 5.000000 | loss: 0.520714 | 
Epoch runtime: 0.0 hours, 27.0 minutes, 9.484996795654297 seconds

Avg epoch train. time: 0.0 hours, 14.0 minutes, 9.527560424804733 seconds
Avg batch train. time: 38.6148891102184 seconds
Avg sample train. time: 0.30405424496234956 seconds
Epoch 6 Training Summary: epoch: 6.000000 | loss: 0.473387 | 
Epoch runtime: 0.0 hours, 8.0 minutes, 45.640077114105225 seconds

Avg epoch train. time: 0.0 hours, 13.0 minutes, 15.54631320635474 seconds
Avg batch train. time: 36.161196054834306 seconds
Avg sample train. time: 0.2847338272034197 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 22.79534888267517 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 25.89869866371155 seconds
Avg batch val. time: 4.316449777285258 seconds
Avg sample val. time: 0.03705107104965887 seconds
Epoch 6 Validation Summary: epoch: 6.000000 | loss: 0.460942 | 
Epoch 7 Training Summary: epoch: 7.000000 | loss: 0.449169 | 
Epoch runtime: 0.0 hours, 8.0 minutes, 29.645398139953613 seconds

Avg epoch train. time: 0.0 hours, 12.0 minutes, 34.70332533972601 seconds
Avg batch train. time: 34.30469660635118 seconds
Avg sample train. time: 0.27011572130985184 seconds
Epoch 8 Training Summary: epoch: 8.000000 | loss: 0.439761 | 
Epoch runtime: 0.0 hours, 11.0 minutes, 11.442689895629883 seconds

Avg epoch train. time: 0.0 hours, 12.0 minutes, 24.29574590921402 seconds
Avg batch train. time: 33.83162481405518 seconds
Avg sample train. time: 0.26639074656736367 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 27.33407998085022 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 26.13792888323466 seconds
Avg batch val. time: 4.35632148053911 seconds
Avg sample val. time: 0.03739331742952026 seconds
Epoch 8 Validation Summary: epoch: 8.000000 | loss: 0.449493 | 
Epoch 9 Training Summary: epoch: 9.000000 | loss: 0.413129 | 
Epoch runtime: 0.0 hours, 10.0 minutes, 43.37267708778381 seconds

Avg epoch train. time: 0.0 hours, 12.0 minutes, 13.0820715957218 seconds
Avg batch train. time: 33.32191234526008 seconds
Avg sample train. time: 0.262377262561103 seconds
Epoch 10 Training Summary: epoch: 10.000000 | loss: 0.411275 | 
Epoch runtime: 0.0 hours, 11.0 minutes, 47.88464903831482 seconds

Avg epoch train. time: 0.0 hours, 12.0 minutes, 10.562329339981034 seconds
Avg batch train. time: 33.207378606362774 seconds
Avg sample train. time: 0.2614754220973447 seconds
Evaluating on validation set ...
Validation runtime: 0.0 hours, 0.0 minutes, 25.517868995666504 seconds

Avg val. time: 0.0 hours, 0.0 minutes, 26.04934889929635 seconds
Avg batch val. time: 4.341558149882725 seconds
Avg sample val. time: 0.03726659356122511 seconds
Epoch 10 Validation Summary: epoch: 10.000000 | loss: 0.451780 | 
Best loss was 0.4494926270880068. Other metrics: OrderedDict([('epoch', 8), ('loss', 0.4494926270880068)])
All Done!
Total runtime: 2.0 hours, 5.0 minutes, 34.195157051086426 seconds

